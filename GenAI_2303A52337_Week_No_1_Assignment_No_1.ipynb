{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/2303A52337/GENERATIVE_AI_2025/blob/main/GenAI_2303A52337_Week_No_1_Assignment_No_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1.Question**"
      ],
      "metadata": {
        "id": "jUlIocVEgdYV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. (1 ponto) Write Python code from scratch to find error metrics of deep learning model. Actual values and deep learning model predicted values are shown in Table 1. Also compare the resultswith the outcomes of libraries**\n",
        "\n",
        "**YActual:[ 20 , 30 , 40 , 50 , 60]**     \n",
        "**YPred: [20.5 , 30.3 , 40.2 , 50.6 , 60.7]**\n",
        "\n",
        "**Tabela 1: YActual Vs. YPred**"
      ],
      "metadata": {
        "id": "4GHVjZ2FwueS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#**Actual and predicted values**"
      ],
      "metadata": {
        "id": "4D3PZOf1qLd7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "y_actual = np.array([20, 30, 40, 50, 60])\n",
        "y_pred = np.array([20.5, 30.3, 40.2, 50.6, 60.7])"
      ],
      "metadata": {
        "id": "o9S2dOlQqj9Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Mean Absolute Error (MAE)**"
      ],
      "metadata": {
        "id": "FN4xHPqgqo-z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mae(y_actual, y_pred):\n",
        "  return np.mean(np.abs(y_actual - y_pred))\n",
        "mae_result = mae(y_actual, y_pred)\n",
        "print(f\"Mean Absolute Error (MAE): {mae_result}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3daqO_XoqypL",
        "outputId": "92a8694f-c9ff-4328-e87f-04d1a264116d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Absolute Error (MAE): 0.4600000000000016\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Mean Squared Error (MSE)**"
      ],
      "metadata": {
        "id": "NDufw2dWq5lP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mse(y_actual, y_pred):\n",
        "  return np.mean(np.square(y_actual - y_pred))\n",
        "mse_result = mse(y_actual, y_pred)\n",
        "print(f\"Mean Squared Error (MSE): {mse_result}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nDf5pvBCrNtO",
        "outputId": "5924d5ac-b5fd-4380-c552-9c40b9d1cf0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error (MSE): 0.24600000000000147\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Root Mean Squared Error (RMSE)**"
      ],
      "metadata": {
        "id": "YdBymF3drOSa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def rmse(y_actual, y_pred):\n",
        "  return np.sqrt(mse(y_actual,y_pred))\n",
        "rmse_result = rmse(y_actual, y_pred)\n",
        "print(f\"Root Mean Squared Error (RMSE): {rmse_result}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mM9cmkYgrOqI",
        "outputId": "9b4c9e06-bb10-420c-f302-bae2f7b59eea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Root Mean Squared Error (RMSE): 0.49598387070549127\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Comparison with libraries (sklearn)**"
      ],
      "metadata": {
        "id": "SyPgTBp-rdex"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "mae_sklearn = mean_absolute_error(y_actual, y_pred)\n",
        "mse_sklearn = mean_squared_error(y_actual, y_pred)\n",
        "rmse_sklearn = np.sqrt(mse_sklearn)\n",
        "\n",
        "print(f\"\\nComparison with scikit-learn:\")\n",
        "print(f\"MAE (sklearn): {mae_sklearn}\")\n",
        "print(f\"MSE (sklearn): {mse_sklearn}\")\n",
        "print(f\"RMSE (sklearn): {rmse_sklearn}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nbaCwX92iTYu",
        "outputId": "ca5dabea-5452-4dd2-d766-f37d1b2b713b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Comparison with scikit-learn:\n",
            "MAE (sklearn): 0.4600000000000016\n",
            "MSE (sklearn): 0.24600000000000147\n",
            "RMSE (sklearn): 0.49598387070549127\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Question 2**"
      ],
      "metadata": {
        "id": "RsaYf0eqszlY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. (1 ponto) Write python code from scratch to find evaluation metrics of deep learning model.Actual values and deep learning model predicted values are** **shown in Table 2. Also compare the results with outcome of libraries**\n",
        "\n",
        "**YActual: [ 0 , 0 , 0 , 0 , 0 ]**\n",
        "\n",
        "**YPred: [0 , 0  , 1 , 2 , 2 ]**\n",
        "\n",
        "**Tabela 2: YActual Vs. YPred**"
      ],
      "metadata": {
        "id": "9pRMjNYos0AO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "#**Actual and predicted values**"
      ],
      "metadata": {
        "id": "cwDAX7wwOQQ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "y_actual = np.array([0, 0, 0, 0, 0])\n",
        "y_pred = np.array([0, 0, 1, 2, 2])"
      ],
      "metadata": {
        "id": "Tq-EawyzOQkc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Mean Absolute Error (MAE)**"
      ],
      "metadata": {
        "id": "6oXUJ10IOl4X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mae(y_actual, y_pred):\n",
        "  return np.mean(np.abs(y_actual - y_pred))\n",
        "mae_result = mae(y_actual, y_pred)\n",
        "print(f\"Mean Absolute Error (MAE): {mae_result}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FVEI0A4rOnJq",
        "outputId": "783c7481-642b-4755-d391-6162bc2fd365"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Absolute Error (MAE): 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Mean Squared Error (MSE)**"
      ],
      "metadata": {
        "id": "SeBxDfyYOos2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mse(y_actual, y_pred):\n",
        "  return np.mean(np.square(y_actual - y_pred))\n",
        "mse_result = mse(y_actual, y_pred)\n",
        "print(f\"Mean Squared Error (MSE): {mse_result}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6mgOoc8fOo9U",
        "outputId": "a618113d-f05a-495a-c87c-cf232fc655c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error (MSE): 1.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Root Mean Squared Error (RMSE)**"
      ],
      "metadata": {
        "id": "z_tQPHgZOxv_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def rmse(y_actual, y_pred):\n",
        "  return np.sqrt(mse(y_actual, y_pred))\n",
        "rmse_result = rmse(y_actual, y_pred)\n",
        "print(f\"Root Mean Squared Error (RMSE): {rmse_result}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kw5JB2GwOx-z",
        "outputId": "d936334c-a341-4167-b666-557897ae83fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Root Mean Squared Error (RMSE): 1.3416407864998738\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Comparison with libraries (sklearn)**"
      ],
      "metadata": {
        "id": "CuPfdLz6PJau"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mae_sklearn = mean_absolute_error(y_actual, y_pred)\n",
        "mse_sklearn = mean_squared_error(y_actual, y_pred)\n",
        "rmse_sklearn = np.sqrt(mse_sklearn)\n",
        "\n",
        "print(f\"\\nComparison with scikit-learn:\")\n",
        "print(f\"MAE (sklearn): {mae_sklearn}\")\n",
        "print(f\"MSE (sklearn): {mse_sklearn}\")\n",
        "print(f\"RMSE (sklearn): {rmse_sklearn}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ovl49yK-PJqU",
        "outputId": "ab6a8ab7-168d-4fb2-8f38-a3b3f2f5476a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Comparison with scikit-learn:\n",
            "MAE (sklearn): 1.0\n",
            "MSE (sklearn): 1.8\n",
            "RMSE (sklearn): 1.3416407864998738\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Additional metrics relevant for classification(since the data seems binary)**"
      ],
      "metadata": {
        "id": "TLCO_1rD0hQs"
      }
    },
    {
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix # Import confusion_matrix\n",
        "\n",
        "accuracy = accuracy_score(y_actual, y_pred)\n",
        "precision = precision_score(y_actual, y_pred, average='micro')\n",
        "recall = recall_score(y_actual, y_pred, average='micro')\n",
        "f1 = f1_score(y_actual, y_pred, average='micro')\n",
        "\n",
        "print(f\"\\nClassification Metrics:\")\n",
        "print(f\"Accuracy: {accuracy}\")\n",
        "print(f\"Precision: {precision}\")\n",
        "print(f\"Recall: {recall}\")\n",
        "print(f\"F1 Score: {f1}\")\n",
        "\n",
        "conf_matrix = confusion_matrix(y_actual, y_pred) # Calculate the confusion matrix\n",
        "\n",
        "print(f\"\\nConfusion Matrix:\")\n",
        "print(conf_matrix)"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iJjztXU8hR75",
        "outputId": "e9d11244-56d4-4dad-fc30-73a45247bf3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Classification Metrics:\n",
            "Accuracy: 0.4\n",
            "Precision: 0.4\n",
            "Recall: 0.4\n",
            "F1 Score: 0.4\n",
            "\n",
            "Confusion Matrix:\n",
            "[[2 1 2]\n",
            " [0 0 0]\n",
            " [0 0 0]]\n"
          ]
        }
      ]
    }
  ]
}